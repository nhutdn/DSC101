{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amphi 8 - Classification [2] - Multiclass Classification. Regularization. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multiclass Classification.\n",
    "\n",
    "Introduction\n",
    "\n",
    "In binary classification, the objective is to classify data points into 2 categories.\n",
    "\n",
    "In multiclass classification, the objective is to classify them into $K$ categories. In this case we can write $\\mathcal Y = \\{0, 1, \\ldots, K-1\\}$.\n",
    "\n",
    "In this section, we learn several strategies to solve multiclass classification problem.\n",
    "\n",
    "\n",
    "## 1.1 One vs Rest\n",
    "\n",
    "In One Vs Rest (OVR) method (also named OVA- One Vs All), we divide our porblem into $K$ binary classification problems. For each problem $k$ ($k = 0$ to $K-1$), we try to predict whether the data point is more likely to be in category $k$ or not in category $k$. In other words, we try to find $K-1$ predictive hypothesis $y^{(0)}, \\ldots, y^{(K-1)}$ for those $K$ binary classifications problems. This predictive hypothesis (recall that it is a function) is usually expressed in probability form ($P(y|\\mathbf x)$). Finally, we choose the category that maximizes this function.\n",
    "\n",
    "In probabilistic form:\n",
    "\n",
    "$$\n",
    "y^{(0)}(\\mathbf x) = P_0(y = 1_0 | \\mathbf x) \\\\\n",
    "y^{(1)}(\\mathbf x) = P_1(y = 1_1 | \\mathbf x) \\\\\n",
    "\\ldots \\\\\n",
    "y^{(K-1)}(\\mathbf x) = P_{K-1}(y = 1_{K-1} | \\mathbf x) \\\\\n",
    "$$\n",
    "\n",
    "Decide $y(\\mathbf x) = \\arg \\max_k y^{(k)}(x)$\n",
    "\n",
    "where $P_k(y = 1_k | \\mathbf x)$ means the probability of $y = 1_k$ given $\\mathbf x$ in the $k^{th}$ binary classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Python\n",
    "\n",
    "Python supports OVA for the following models:\n",
    "\n",
    "- **sklearn.svm.LinearSVC** (setting multi_class=\"ovr\") (SVM will be presented in next lecture)\n",
    "- **sklearn.linear_model.LogisticRegression** (setting multi_class=\"ovr\")\n",
    "- **sklearn.linear_model.LogisticRegressionCV** (setting multi_class=\"ovr\")\n",
    "- **sklearn.linear_model.Perceptron** ($\\arg \\max w_k \\cdot x$ instead of probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "We use an example in [1] for fruit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>fruit_subtype</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>192</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>180</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>176</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>86</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fruit_label fruit_name fruit_subtype  mass  width  height  color_score\n",
       "0            1      apple  granny_smith   192    8.4     7.3         0.55\n",
       "1            1      apple  granny_smith   180    8.0     6.8         0.59\n",
       "2            1      apple  granny_smith   176    7.4     7.2         0.60\n",
       "3            2   mandarin      mandarin    86    6.2     4.7         0.80\n",
       "4            2   mandarin      mandarin    84    6.0     4.6         0.79"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('fruit_data_with_colors.txt', sep = \"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 7)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fruit_name\n",
       "apple       19\n",
       "lemon       16\n",
       "mandarin     5\n",
       "orange      19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('fruit_name').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'mandarin', 'orange', 'lemon'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['fruit_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mass  width  height  color_score\n",
       "0   192    8.4     7.3         0.55\n",
       "1   180    8.0     6.8         0.59\n",
       "2   176    7.4     7.2         0.60\n",
       "3    86    6.2     4.7         0.80\n",
       "4    84    6.0     4.6         0.79"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:, [\"mass\", \"width\", \"height\", \"color_score\"]]\n",
    "y = data.loc[:, \"fruit_label\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.58913538e-01, 5.79678244e-10, 6.41084986e-01, 1.47549370e-06],\n",
       "       [3.80022675e-01, 1.45205396e-02, 1.80228228e-01, 4.25228557e-01],\n",
       "       [6.65960497e-02, 8.14078835e-05, 2.00232934e-01, 7.33089609e-01],\n",
       "       [4.71493119e-01, 2.55799515e-02, 2.29768655e-01, 2.73158275e-01],\n",
       "       [4.26632738e-01, 2.14316517e-03, 4.82735210e-01, 8.84888869e-02],\n",
       "       [5.24513071e-01, 2.08005261e-03, 4.54774529e-01, 1.86323474e-02],\n",
       "       [5.15904203e-01, 6.96963726e-02, 1.01013818e-01, 3.13385606e-01],\n",
       "       [7.80465248e-02, 1.26764354e-05, 4.10608685e-01, 5.11332113e-01],\n",
       "       [5.02069160e-01, 1.25641020e-02, 2.85877856e-01, 1.99488882e-01],\n",
       "       [6.17601418e-01, 7.07567307e-02, 1.72900608e-01, 1.38741242e-01],\n",
       "       [4.20928359e-01, 4.84431271e-01, 5.66334533e-02, 3.80069164e-02],\n",
       "       [4.34393487e-01, 2.95626932e-03, 4.80154371e-01, 8.24958735e-02],\n",
       "       [4.97416822e-01, 8.59337571e-03, 3.31211595e-01, 1.62778207e-01],\n",
       "       [4.61597704e-01, 1.93976127e-03, 4.19746178e-01, 1.16716357e-01],\n",
       "       [4.06680081e-01, 5.68525956e-04, 5.36497009e-01, 5.62543839e-02]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, 1, 3, 1, 1, 4, 1, 1, 2, 3, 1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 3, 1, 1, 3, 4, 3, 1, 2, 1, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.35005139e-04,  7.90924593e-01, -7.04427722e-01,\n",
       "         -3.88166421e-01],\n",
       "        [-9.46061077e-02,  1.64318922e+00, -3.15227059e-01,\n",
       "          2.93015193e-01],\n",
       "        [ 4.90830914e-02, -6.38562401e-01, -5.97765143e-01,\n",
       "          1.57700706e-01],\n",
       "        [-5.58379989e-02, -1.32093343e+00,  2.19077744e+00,\n",
       "         -1.90468678e-01]]),\n",
       " array([-0.6376886 ,  0.33012073, -0.02983125, -0.10378818]))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=1000, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(max_iter = 1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 43191.8664,  -1240.0788,  28776.0978, -38699.2622],\n",
       "       [ 13658.04  ,   -182.215 , -22435.7225,    939.6775],\n",
       "       [ 10536.842 ,   -390.834 , -20916.471 ,   4026.029 ],\n",
       "       [ 13972.8092,   -168.8264, -19899.0216,   -597.0016],\n",
       "       [ 17354.1312,   -318.1704, -13864.3376,  -5092.0176],\n",
       "       [ 20430.776 ,   -331.652 , -11704.958 ,  -8254.758 ],\n",
       "       [ 14831.31  ,    -98.635 , -26585.9825,   1466.9175],\n",
       "       [ 13893.3756,   -517.2102, -13741.7113,  -1090.0513],\n",
       "       [ 15592.1108,   -213.9236, -19114.5834,  -1909.4034],\n",
       "       [ 16059.3632,   -121.8494, -22438.4661,  -1333.1461],\n",
       "       [ 13893.0044,     64.9002, -22275.8237,  -1028.2837],\n",
       "       [ 17020.4048,   -303.1466, -13434.5279,  -5152.2479],\n",
       "       [ 16069.7744,   -237.7998, -17829.1237,  -2726.6837],\n",
       "       [ 17920.8844,   -318.0598, -16400.9037,  -4260.9637],\n",
       "       [ 19144.2364,   -388.2188, -12241.1222,  -6682.3822]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is not linearly separable, perceptron algorithm does not converge. The algorithm's accuracy is very poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 One vs One\n",
    "\n",
    "We are working with $K$ class, we can use $K(K-1)/2$ binary classifiers for each pair of categories and find the following predictive hypothesis:\n",
    "\n",
    "$$\n",
    "y^{(0,1)}(\\mathbf x) = 1 - y^{(1,0)}(\\mathbf x) = P_{0, 1}(y = 0_{0,1} | \\mathbf x) \\\\\n",
    "y^{(0,2)}(\\mathbf x) = 1 - y^{(1,2)}(\\mathbf x) = P_{0, 2}(y = 0_{0,2} | \\mathbf x) \\\\\n",
    "\\ldots \\\\\n",
    "y^{(K-1,K)}(\\mathbf x) = 1 - y^{(K,K-1)}(\\mathbf x) = P_{K-1}(y = 0_{K-1,K} | \\mathbf x) \\\\\n",
    "$$\n",
    "\n",
    "We can replace $P_{i, j}(y = 0_{i,j} | \\mathbf x) $ in each line by $\\mathbf 1_{i,j}$ if the model is not probabilistic.\n",
    "\n",
    "Finally, we find $k$ that maximizes:\n",
    "\n",
    "$$\n",
    "\\sum_{j \\neq k} y^{(k, j)}(\\mathbf x)\n",
    "$$\n",
    "\n",
    "In perfect model, this sum is $K-1$ for the correct class and $\\leq K - 2$ for other classes. In case where $\\mathbf 1_{i,j}$ is used instead of $P_{i, j}$, this is nothing but majority vote between the $K$ classifiers after a full pairwise classification procedure.\n",
    "\n",
    "This method is called One vs One (OVO)\n",
    "\n",
    "**Comparison with OVR**\n",
    "\n",
    "OVO needs $N(N-1)/2$ classifiers, that is usually longer than OVR (OVA).\n",
    "\n",
    "However, it can solve some non-linearly separable cases that OVR cannot (case 2 and 3 below)\n",
    "\n",
    "<img src=\"F1.png\"></img>\n",
    "<center>Illustration from [2]</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Python\n",
    "\n",
    "Python supports OVA for the following models:\n",
    "\n",
    "- **sklearn.svm.LinearSVC** (setting decision_function_shape = \"one_vs_one\") (SVM will be presented in next lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='one_vs_one', degree=3, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(decision_function_shape = \"one_vs_one\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59977971,  0.12767047,  0.05004476, -0.57771012, -0.58701971,\n",
       "        -0.00110858],\n",
       "       [ 0.70807823,  0.42621142,  0.06759398, -0.58454003, -0.71385522,\n",
       "        -0.2884136 ],\n",
       "       [ 0.61053631,  0.15126831, -0.25978597, -0.57766006, -0.72335224,\n",
       "        -0.33106619],\n",
       "       [ 0.59977971,  0.10992964,  0.05004472, -0.58520971, -0.58701973,\n",
       "         0.01663222],\n",
       "       [ 0.97115902,  0.93707963,  0.88572994, -0.5776601 , -0.61821883,\n",
       "        -0.07668509],\n",
       "       [ 0.715493  ,  0.38000495,  0.28220759, -0.57766006, -0.60545543,\n",
       "        -0.04581568],\n",
       "       [ 0.59977971, -0.17340517,  0.05004476, -0.70498296, -0.58701971,\n",
       "         0.29996706],\n",
       "       [ 0.59977971,  0.12775458,  0.05004476, -0.57767461, -0.58701971,\n",
       "        -0.00119268],\n",
       "       [ 1.00029759,  0.02133426,  0.94503665, -0.99183384, -0.69502887,\n",
       "         0.93229877],\n",
       "       [ 0.59977971,  0.11102636,  0.05004473, -0.5847461 , -0.58701973,\n",
       "         0.01553551],\n",
       "       [ 0.20829651,  0.12778904,  0.05004476, -0.1865601 , -0.19575374,\n",
       "        -0.00122715],\n",
       "       [ 0.82156224,  0.37293524,  0.57632399, -0.72372147, -0.58701972,\n",
       "         0.34501144],\n",
       "       [ 0.83358982, -0.65482182,  0.59392957, -0.99753247, -0.58705594,\n",
       "         0.99477366],\n",
       "       [ 0.89753784,  0.77654017,  0.75788991, -0.57766006, -0.58707796,\n",
       "        -0.00136806],\n",
       "       [ 0.70123518,  0.34924369,  0.27853255, -0.57766006, -0.59250755,\n",
       "        -0.01450634]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 4, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 3, 1, 1, 3, 4, 3, 1, 2, 1, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Hierarchical Methods\n",
    "\n",
    "We can combine advantages of OVR and OVO to describe intermediate methods for multiclass classifications. For example: given categories $\\{0, 1, \\ldots, K-1 = 2^n - 1 \\}$ ($K = 2^n$ categories), using OVO is time infeasible while using OVR may yeild to linear inseparability. We can use OVO in a smarter way:\n",
    "\n",
    "- Classify $\\{0, 1, \\ldots, 2^{n-1}-1\\}$ with $\\{ 2^{n-1}, \\ldots, 2^n -1 \\}$ (first half with second half)\n",
    "- Then for each half, divide into two smaller halves (quarters) and classify them.\n",
    "\n",
    "This method reduces the complexity to $K$ instead of $K^2$ in terms of number of binary classifications. The method is called **hierarchical**. The disadvantage is that we do not know if the division into halves can make the problem linearly separable.\n",
    "\n",
    "We can even improve this complexity to $O(\\log K)$, write every $k \\in \\{0, \\ldots, K-1\\}$ in binary forms: $xxx\\ldots x$ ($n$ digits) and classify by digits. \n",
    "\n",
    "Those methods are generally not implemented in scikit learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Using Multinomial Distribution\n",
    "\n",
    "This method will be detailed in section 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multinomial Distribution and Applications\n",
    "\n",
    "## 2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Binary Distribution tables** (Probabilistic methods)\n",
    "\n",
    "| Model                 | Probabilistic Model   Representation                                                                                                                                                         |                                 |                                                   |Solution                         |                                        |\n",
    "|-----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------|---------------------------------------------------|----------------------------------|----------------------------------------|\n",
    "|                       | Probability Distribution                                                                                                                                                                     | Parameters                      | Optimization Problem                              | Solution                         | Decision Rule                          |\n",
    "| LDA                   | $P(y)$ follow Bernoulli$(\\pi)$,        $p(x|y)$ follow Gaussian$(\\mu_y, \\Sigma)$,      $(x_i, y_i)$ independent                                                                              | $\\pi, \\mu_y, \\Sigma$            | ML     $p(x_1, \\ldots, x_N, y_1, \\ldots, y_N)$    |      (section 5)                 | argmax_y $P(y|x)$                      |                                                                    |\n",
    "| QDA                   | $P(y)$ follow Bernoulli$(\\pi)$,        $p(x|y)$ follow Gaussian$(\\mu_y, \\Sigma_y)$,      $(x_i, y_i)$ independent                                                                            | $\\pi, \\mu_y, \\Sigma_y$          | ML     $p(x_1, \\ldots, x_N, y_1, \\ldots, y_N)$    |      (section 6)                 | argmax_y $P(y|x)$                      |                                                                    |\n",
    "| Logistic Regression   | $P(y|x) = \\frac1{1 +   \\exp(-w\\cdot x - b}$,      $y_i$ independent conditionned on $x_i$                                                                                               | $w, b$                          | ML     $p(y_1, \\ldots, y_N| x_1, \\ldots, x_N)$    | Iterative methods                | $1_{w \\cdot x + b > 0}$, argmax_y $P(y|x)$                      |                                                                    |\n",
    "| Gaussian Naïve Bayes  | $P(y)$ follows Bernoulli$(\\pi)$,        The features $x^{(i)}$ of $x$ are independent,      $p(x^{(i)}|y) $ follows Gaussian$(\\mu_y^{(i)}, \\Sigma_y^{(i)})$                                  | $\\pi, \\mu_y^{i}, \\sigma_y^{i}$  | ML     $p(x_1, \\ldots, x_N, y_1, \\ldots, y_N)$    |     (section 9)                 | argmax_y $P(y|x)$                      |                                                                    |\n",
    "| K Nearest Neighbors   | $P(y) = \\frac{N_y}{N}$,      $P(x|y) = \\frac{K_y}{N_y}|\\mathcal R|$ where $\\mathcal R$ a ball containing   $K$ points                                                                        | Not a parametric model.         |  No optimization problem                          |   No optimization problem         | Majority vote     (as $P(y|x) = K_y/K$ |                                                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table, we see our probability distribution hypothesis for binary classifiers are of the form \n",
    "\n",
    "$$\n",
    "P(y) \\sim \\mathrm{Bernoulli}(\\pi)\n",
    "$$\n",
    "\n",
    "(for LDA, QDA, GNB, KNN). In case of KNN, $\\pi = N_1/N$.\n",
    "\n",
    "or\n",
    "$$\n",
    "P(y|x) \\sim \\mathrm{Bernoulli}(\\pi(x))\n",
    "$$\n",
    "\n",
    "(for Logistic Regression). In this case, $\\pi(x) = w \\cdot x$.\n",
    "\n",
    "Bernoulli distribution is a random binary variable. We would like to generalize this variable to multivalue case. This yields to **multinomial distribution**.\n",
    "\n",
    "In multinomial distribution, we have a random variable that can get 1 of $K$ values. We will express this random variable as $y = (y_1, y_2, \\ldots, y_K)$ where only one coordinate is 1, the others are 0. The probability that the coordinate $k$ is 1 is $\\pi_k$. Let $\\mathbf \\pi = (\\pi_1, \\ldots, \\pi_K)$. Then:\n",
    "\n",
    "$$\n",
    "p(\\mathbf y) = \\prod_{k=1}^K \\pi_k^{y_k} \n",
    "$$\n",
    "\n",
    "where $\\sum_k \\pi_k = 1$.\n",
    "\n",
    "Now suppose $y$ or $y|x$ follows multinomial distribution of parameter $\\mathbf \\pi$, we can generalize probabilistic multiclass classification models from binary ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Applications\n",
    "\n",
    "### 2.2.1 LDA\n",
    "\n",
    "In multiclass classification, the hypothesis of LDA for prior distribution of categories $\\mathcal C_1, \\ldots, \\mathcal C_K$ is:\n",
    "\n",
    "$$\n",
    "\\mathbf P(\\mathcal C_k) = \\mathbf P(y = (0, \\ldots, 0, 1, 0, \\ldots, 0)) = \\pi_k\n",
    "$$\n",
    "\n",
    "(1 at $k^{th}$ position(\n",
    "\n",
    "or equivalently\n",
    "\n",
    "$$\n",
    "\\mathbf P(y) = \\prod_{k=1}^K \\pi_k^{y_{(k)}} \n",
    "$$\n",
    "\n",
    "The probability distribution $p(x | \\mathcal C_k)$ still follow Gaussian distribution ($\\mu_k, \\Sigma$):\n",
    "\n",
    "$$\n",
    "p(\\mathbf x|\\mathcal C_k) = \\mathcal N (\\mathbf x_i | \\mu_k, \\Sigma)\n",
    "$$\n",
    "\n",
    "or equivalently\n",
    "$$\n",
    "p(\\mathbf x|y) = \\prod_{k=1}^K \\left( \\mathcal N (\\mathbf x_i | \\mu_k, \\Sigma) \\right)^{y_k}\n",
    "$$\n",
    "\n",
    "The observations are iid, so:\n",
    "\n",
    "$$\n",
    "p(\\mathbf x_1, \\ldots, \\mathbf x_N, y_1, \\ldots, y_N) = \\prod_{i=1}^{N} \\prod_{k=1}^{K}  \\left[ \\pi_k \\delta_1 \\mathcal N (\\mathbf x_i | \\mu_k, \\Sigma)\\right]^{y_{i,k}} \n",
    "$$\n",
    "\n",
    "where $\\pi_1, \\ldots, \\pi_k$.\n",
    "\n",
    "The negative log likelihood is now\n",
    "\n",
    "$$\n",
    "L(\\pi_1, \\ldots, \\pi_K, \\mu_0, \\ldots, \\mu_K) = -\\sum_{i=1}^N \\sum_{k=1}^K (y_{i,k}\\log \\pi_k + y_{i,k} \\log \\mathcal N(\\mathbf x_i | \\mu_k, \\Sigma))\n",
    "$$\n",
    "\n",
    "where $\\sum_{k=1}^K \\pi_k = 1$.\n",
    "\n",
    "Maximum likelihood solution of $L$ for $\\pi_k, \\mu_k, \\Sigma$ ($k=1, \\ldots, K$) can be obtained similarly:\n",
    "\n",
    "$$\n",
    "\\pi_k = \\frac{N_k}N\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_k = \\frac1{N_k}\\sum_{\\mathcal C_k} \\mathbf x_i\n",
    "$$\n",
    "\n",
    "for $k = 1, \\ldots, K$,\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\Sigma = \\sum_k \\frac{N_k}N S_k\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "S_k = \\frac1{N_k} \\sum_{\\mathcal C_k} (\\mathbf x_i - \\mu_k)(\\mathbf x_i - \\mu_k)^t, \\qquad k = 1, \\ldots, K\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 QDA\n",
    "\n",
    "QDA for multiclass classification is similar to LDA, but do not share the same covariance matrix. So the hypothesis is:\n",
    "\n",
    "$$\n",
    "\\mathbf P(y) = \\prod_{k=1}^K \\pi_k^{y_{(k)}} \n",
    "$$\n",
    "\n",
    "$$\n",
    "p(\\mathbf x|y) = \\prod_{k=1}^K \\left( \\mathcal N (\\mathbf x_i | \\mu_k, \\Sigma_k) \\right)^{y_k}\n",
    "$$\n",
    "\n",
    "We want to maximize\n",
    "$$\n",
    "p(\\mathbf x_1, \\ldots, \\mathbf x_N, y_1, \\ldots, y_N) = \\prod_{i=1}^{N} \\prod_{k=1}^{K}  \\left[ \\pi_k \\delta_1 \\mathcal N (\\mathbf x_i | \\mu_k, \\Sigma)\\right]^{y_{i,k}} \n",
    "$$\n",
    "\n",
    "The solution is:\n",
    "$$\n",
    "\\pi_k = \\frac{N_k}N\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_k = \\frac1{N_k}\\sum_{\\mathcal C_k} \\mathbf x_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_k = \\frac1{N_k} \\sum_{\\mathcal C_k} (\\mathbf x_i - \\mu_k)(\\mathbf x_i - \\mu_k)^t\n",
    "$$\n",
    "\n",
    "for $k = 1, \\ldots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Gaussian Naive Bayes\n",
    "\n",
    "Gaussian Naive Bayes is QDA where features of $\\mathbf x$ are mutually independent.\n",
    "\n",
    "The hypothesis is:\n",
    "$$\n",
    "\\mathbf P(y) = \\prod_{k=1}^K \\pi_k^{y_{(k)}}\n",
    "$$\n",
    "\n",
    "For each feature $i$ of $\\mathbf x = (x^{(1)}, \\ldots, x^{(D)})$.\n",
    "$$\n",
    "P(x^{(i)} | y = \\mathcal C_k, x^{(1)}, \\dots, x^{({i-1})}, x^{({i+1})}, \\dots, x^{(D)}) = P(x^{(i)} | \\mathcal C_k)  = \\frac{1}{\\sqrt{2\\pi\\sigma^2_k}} \\exp\\left(-\\frac{(x^{(i)} - \\mu_k)^2}{2\\sigma^2_k}\\right)\n",
    "$$\n",
    "\n",
    "We maximize:\n",
    "$$\n",
    "\\prod_{n=1}^N \\prod_{k=1}^K \\left( p(y_{n,k}) \\prod_{i=1}^{D} p(x_n^{(i)} \\mid y_{n,k}) \\right)\n",
    "$$\n",
    "\n",
    "The solution is:\n",
    "\n",
    "$$\n",
    "\\pi_k = \\frac{N_k}N\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mu_k = \\frac1{N_k}\\sum_{\\mathcal C_k} \\mathbf x_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "(\\sigma_k^{(i)}) ^{2}= \\frac {1}{|\\mathcal C_k|} \\sum _{y_n = k}\\left( x_n^{(i)} -\\mu_k^{(i)} \\right)^2 \n",
    "$$\n",
    "\n",
    "for $k = 1, \\ldots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 K-Nearest Neighbors\n",
    "\n",
    "Nothing changes wrt binary case. We still deduce the rule of majority vote.\n",
    "\n",
    "$$\n",
    "y = \\arg\\max_k \\frac{K_k}K\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Logistic Regression\n",
    "\n",
    "In multiclass classification, we suppose each class correspond to a vector $\\mathbf w_{(k)}$, $y | \\mathbf x$ follows:\n",
    "\n",
    "$$\n",
    "p(y|\\mathbf x) = \\frac{\\exp(\\mathbf w_{(k)} \\cdot \\mathbf x)}{\\sum_{j=1}^K \\exp(\\mathbf w_{(j)} \\cdot \\mathbf x)}\n",
    "$$\n",
    "\n",
    "By iid hypothesis,\n",
    "\n",
    "$$\n",
    "p(y_1, \\ldots, y_N | \\mathbf x_1, \\ldots, \\mathbf x_N) = \\prod_{n=1}^N \\prod_{k=1}^K p(\\mathcal C_k | \\mathbf x_n)^{y_{(n,k)}}\n",
    "$$\n",
    "\n",
    "This optimization is again, solved by iterative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Summary\n",
    "\n",
    "** Multiclass Classification models** (Probabilistic methods)\n",
    "\n",
    "| Model                 | Probabilistic Model   Representation                                                                                                                                                         |                                 |                                                   |Solution                         |                                        |\n",
    "|-----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------|---------------------------------------------------|----------------------------------|----------------------------------------|\n",
    "|                       | Probability Distribution                                                                                                                                                                     | Parameters                      | Optimization Problem                              | Solution                         | Decision Rule                          |\n",
    "| LDA                   | $P(y)$ follow Multinomial$(\\pi)$,        $p(x|y)$ follow Gaussian$(\\mu_y, \\Sigma)$,      $(x_i, y_i)$ independent                                                                              | $\\pi, \\mu_y, \\Sigma$            | ML     $p(x_1, \\ldots, x_N, y_1, \\ldots, y_N)$    |      (section 5)                 | argmax_y $P(y|x)$                      |                                                                    |\n",
    "| QDA                   | $P(y)$ follow Multinomial$(\\pi)$,        $p(x|y)$ follow Gaussian$(\\mu_y, \\Sigma_y)$,      $(x_i, y_i)$ independent                                                                            | $\\pi, \\mu_y, \\Sigma_y$          | ML     $p(x_1, \\ldots, x_N, y_1, \\ldots, y_N)$    |      (section 6)                 | argmax_y $P(y|x)$                      |                                                                    |\n",
    "| Logistic Regression   | $P(\\mathcal C_k|x) = \\frac{\\exp(-w_{(k)}\\cdot x - b_k)}{\\sum_j   \\exp(-w_{(j)}\\cdot x - b_j})$,      $y_i$ independent conditionned on $x_i$                                                                                               | $w, b$                          | ML     $p(y_1, \\ldots, y_N| x_1, \\ldots, x_N)$    | Iterative methods                | $1_{w \\cdot x + b > 0}$, argmax_y $P(y|x)$                      |                                                                    |\n",
    "| Gaussian Naïve Bayes  | $P(y)$ follows Bernoulli$(\\pi)$,        The features $x^{(i)}$ of $x$ are independent,      $p(x^{(i)}|y) $ follows Gaussian$(\\mu_y^{(i)}, \\Sigma_y^{(i)})$                                  | $\\pi, \\mu_y^{i}, \\sigma_y^{i}$  | ML     $p(x_1, \\ldots, x_N, y_1, \\ldots, y_N)$    |     (section 9)                 | argmax_y $P(y|x)$                      |                                                                    |\n",
    "| K Nearest Neighbors   | $P(y) = \\frac{N_y}{N}$,      $P(x|y) = \\frac{K_y}{N_y}|\\mathcal R|$ where $\\mathcal R$ a ball containing   $K$ points                                                                        | Not a parametric model.         |  No optimization problem                          |   No optimization problem         | Majority vote     (as $P(y|x) = K_y/K$ |                                                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Implementation in Python\n",
    "\n",
    "Methods based on multinomial distribution are implemented in many classes of scikit learn, including:\n",
    "\n",
    "- **sklearn.naive_bayes.GaussianNB**\n",
    "- **sklearn.neighbors.KNeighborsClassifier**\n",
    "- **sklearn.discriminant_analysis.LinearDiscriminantAnalysis**\n",
    "- **sklearn.svm.LinearSVC** (setting multi_class=”crammer_singer”)\n",
    "- **sklearn.linear_model.LogisticRegression** (setting multi_class='multinomial')\n",
    "- **sklearn.linear_model.LogisticRegressionCV** (setting multi_class='multinomial')\n",
    "- **sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis**\n",
    "\n",
    "**Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=True, tol=0.0001)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.73268973e-01, 5.01315461e-07, 5.26730526e-01, 3.39960053e-11],\n",
       "       [2.52863395e-01, 4.76790741e-09, 7.46123283e-01, 1.01331738e-03],\n",
       "       [2.41348548e-07, 3.11014272e-21, 2.15035414e-03, 9.97849405e-01],\n",
       "       [6.96744300e-02, 9.97879282e-06, 9.27388285e-01, 2.92730665e-03],\n",
       "       [4.30177654e-01, 2.68249342e-06, 5.69819638e-01, 2.53215010e-08],\n",
       "       [1.43999671e-01, 1.37561459e-05, 8.55875888e-01, 1.10684110e-04],\n",
       "       [7.95990565e-01, 2.25132079e-09, 2.04009422e-01, 1.01315202e-08],\n",
       "       [1.99438885e-07, 9.10404389e-20, 4.60877060e-03, 9.95391030e-01],\n",
       "       [4.02143431e-01, 4.40021081e-07, 5.97851099e-01, 5.02948690e-06],\n",
       "       [6.14979825e-01, 2.78517161e-05, 3.84992323e-01, 1.51158263e-11],\n",
       "       [3.50845231e-01, 5.18565037e-01, 1.30589732e-01, 1.21752774e-11],\n",
       "       [3.48429371e-01, 4.94119567e-05, 6.51521191e-01, 2.64027786e-08],\n",
       "       [3.51780578e-01, 6.99214146e-07, 6.48214725e-01, 3.99792170e-06],\n",
       "       [5.45943207e-01, 1.64429460e-09, 4.54055935e-01, 8.56014461e-07],\n",
       "       [1.35963994e-01, 1.06008009e-08, 8.63946882e-01, 8.91135524e-05]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 3, 3, 3, 1, 4, 3, 1, 2, 3, 3, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 3, 1, 1, 3, 4, 3, 1, 2, 1, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34090909, 0.09090909, 0.25      , 0.31818182])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165.46666667,   7.53333333,   7.35333333,   0.77133333],\n",
       "       [ 80.5       ,   5.925     ,   4.325     ,   0.7975    ],\n",
       "       [200.54545455,   7.57272727,   7.95454545,   0.78090909],\n",
       "       [142.14285714,   6.40714286,   8.65714286,   0.72      ]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68170852e+03,  1.98174095e+01,  2.10894343e+01,\n",
       "        -3.47495179e-01],\n",
       "       [ 1.98174095e+01,  2.88453119e-01,  2.61624606e-01,\n",
       "        -1.20714532e-02],\n",
       "       [ 2.10894343e+01,  2.61624606e-01,  4.54236177e-01,\n",
       "        -3.09573003e-05],\n",
       "       [-3.47495179e-01, -1.20714532e-02, -3.09573003e-05,\n",
       "         4.64407369e-03]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.covariance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.40401567e-02, 2.54059122e-44, 9.35959544e-01, 2.99235568e-07],\n",
       "       [3.89555579e-01, 2.31945812e-08, 2.51903333e-01, 3.58541065e-01],\n",
       "       [1.20984203e-02, 5.54873835e-16, 6.65254968e-02, 9.21376083e-01],\n",
       "       [4.85879965e-01, 8.74577979e-07, 3.48158131e-01, 1.65961029e-01],\n",
       "       [4.29194950e-01, 4.96749084e-12, 5.19309721e-01, 5.14953285e-02],\n",
       "       [5.76125005e-01, 6.96345625e-13, 4.13414726e-01, 1.04602697e-02],\n",
       "       [6.29053874e-01, 3.59889539e-07, 1.22632456e-01, 2.48313310e-01],\n",
       "       [3.96475630e-02, 3.88614907e-19, 3.69113689e-01, 5.91238748e-01],\n",
       "       [5.32414134e-01, 4.68581893e-09, 3.42163311e-01, 1.25422551e-01],\n",
       "       [7.43017798e-01, 6.25793660e-07, 1.80320537e-01, 7.66610392e-02],\n",
       "       [2.53069628e-03, 9.97020299e-01, 4.01908227e-04, 4.70961517e-05],\n",
       "       [4.20981119e-01, 4.30991847e-11, 5.35999331e-01, 4.30195499e-02],\n",
       "       [5.19256691e-01, 1.02417983e-09, 3.81604835e-01, 9.91384727e-02],\n",
       "       [5.06457196e-01, 2.97352334e-13, 4.07042578e-01, 8.65002260e-02],\n",
       "       [4.17144010e-01, 5.98085486e-15, 5.43933120e-01, 3.89228707e-02]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 4, 1, 3, 1, 1, 4, 1, 1, 2, 3, 1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 3, 1, 1, 3, 4, 3, 1, 2, 1, 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Regularization in Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation of Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Confusion matrix. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent the number of data points correctly classified by a matrix $M$ where $M_{ij}$ represents the number of points of true class $C_i$ classified as $C_j$. This matrix is called **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 3, 4, 3, 1, 1, 3, 4, 3, 1, 2, 1, 3, 3, 3], dtype=int64),\n",
       " array([3, 4, 4, 1, 3, 1, 1, 4, 1, 1, 2, 3, 1, 1, 3], dtype=int64))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_test.values, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 2, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [5, 0, 2, 1],\n",
       "       [0, 0, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion matrix\")\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **normalized confusion matrix** is defined by dividing the **confusion matrix** by the total number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.13333333, 0.        , 0.13333333, 0.        ],\n",
       "       [0.        , 0.06666667, 0.        , 0.        ],\n",
       "       [0.33333333, 0.        , 0.13333333, 0.06666667],\n",
       "       [0.        , 0.        , 0.        , 0.13333333]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "M = confusion_matrix(y_test, y_pred)\n",
    "normalized_M = M/np.sum(M)\n",
    "print(\"Normalized confusion matrix\")\n",
    "normalized_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **accuracy** is the number of data points correctly classified. It is the normalized confusion matrix' **trace**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of normalized confusion matrix\n",
      "0.4666666666666667\n",
      "Accuracy\n",
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Trace of normalized confusion matrix\")\n",
    "print(sum(np.diagonal(normalized_M)))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 True Positive/Negative Rate, Precision, Recall, F1 for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 True Positive, True Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some binary classification problem, we prefer one class than the other and call the former \"positive class\", the latter \"negative class\", denoted by 1 and 0 respectively.\n",
    "\n",
    "Consider the same dataset but now we want to classify into 2 classes: apple and orange(0), mandarin and lemon (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>fruit_subtype</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>192</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>180</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>176</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>178</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>172</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>166</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>172</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>braeburn</td>\n",
       "      <td>154</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>164</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>152</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>156</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>156</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>golden_delicious</td>\n",
       "      <td>168</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>162</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>162</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>160</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>156</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>140</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cripps_pink</td>\n",
       "      <td>170</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spanish_jumbo</td>\n",
       "      <td>342</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spanish_jumbo</td>\n",
       "      <td>356</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>spanish_jumbo</td>\n",
       "      <td>362</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>204</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>140</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>160</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>158</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>210</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selected_seconds</td>\n",
       "      <td>164</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>190</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>142</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>150</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>160</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>154</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>158</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>144</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>154</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>180</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>turkey_navel</td>\n",
       "      <td>154</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>194</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>200</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>186</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>216</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>196</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spanish_belsan</td>\n",
       "      <td>174</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>132</td>\n",
       "      <td>5.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>130</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>118</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>120</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>116</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>152</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>118</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fruit_label  fruit_name     fruit_subtype  mass  width  height  \\\n",
       "0             0           0      granny_smith   192    8.4     7.3   \n",
       "1             0           0      granny_smith   180    8.0     6.8   \n",
       "2             0           0      granny_smith   176    7.4     7.2   \n",
       "3             1           1                 1    86    6.2     4.7   \n",
       "4             1           1                 1    84    6.0     4.6   \n",
       "5             1           1                 1    80    5.8     4.3   \n",
       "6             1           1                 1    80    5.9     4.3   \n",
       "7             1           1                 1    76    5.8     4.0   \n",
       "8             0           0          braeburn   178    7.1     7.8   \n",
       "9             0           0          braeburn   172    7.4     7.0   \n",
       "10            0           0          braeburn   166    6.9     7.3   \n",
       "11            0           0          braeburn   172    7.1     7.6   \n",
       "12            0           0          braeburn   154    7.0     7.1   \n",
       "13            0           0  golden_delicious   164    7.3     7.7   \n",
       "14            0           0  golden_delicious   152    7.6     7.3   \n",
       "15            0           0  golden_delicious   156    7.7     7.1   \n",
       "16            0           0  golden_delicious   156    7.6     7.5   \n",
       "17            0           0  golden_delicious   168    7.5     7.6   \n",
       "18            0           0       cripps_pink   162    7.5     7.1   \n",
       "19            0           0       cripps_pink   162    7.4     7.2   \n",
       "20            0           0       cripps_pink   160    7.5     7.5   \n",
       "21            0           0       cripps_pink   156    7.4     7.4   \n",
       "22            0           0       cripps_pink   140    7.3     7.1   \n",
       "23            0           0       cripps_pink   170    7.6     7.9   \n",
       "24            0           0     spanish_jumbo   342    9.0     9.4   \n",
       "25            0           0     spanish_jumbo   356    9.2     9.2   \n",
       "26            0           0     spanish_jumbo   362    9.6     9.2   \n",
       "27            0           0  selected_seconds   204    7.5     9.2   \n",
       "28            0           0  selected_seconds   140    6.7     7.1   \n",
       "29            0           0  selected_seconds   160    7.0     7.4   \n",
       "30            0           0  selected_seconds   158    7.1     7.5   \n",
       "31            0           0  selected_seconds   210    7.8     8.0   \n",
       "32            0           0  selected_seconds   164    7.2     7.0   \n",
       "33            0           0      turkey_navel   190    7.5     8.1   \n",
       "34            0           0      turkey_navel   142    7.6     7.8   \n",
       "35            0           0      turkey_navel   150    7.1     7.9   \n",
       "36            0           0      turkey_navel   160    7.1     7.6   \n",
       "37            0           0      turkey_navel   154    7.3     7.3   \n",
       "38            0           0      turkey_navel   158    7.2     7.8   \n",
       "39            0           0      turkey_navel   144    6.8     7.4   \n",
       "40            0           0      turkey_navel   154    7.1     7.5   \n",
       "41            0           0      turkey_navel   180    7.6     8.2   \n",
       "42            0           0      turkey_navel   154    7.2     7.2   \n",
       "43            1           1    spanish_belsan   194    7.2    10.3   \n",
       "44            1           1    spanish_belsan   200    7.3    10.5   \n",
       "45            1           1    spanish_belsan   186    7.2     9.2   \n",
       "46            1           1    spanish_belsan   216    7.3    10.2   \n",
       "47            1           1    spanish_belsan   196    7.3     9.7   \n",
       "48            1           1    spanish_belsan   174    7.3    10.1   \n",
       "49            1           1           unknown   132    5.8     8.7   \n",
       "50            1           1           unknown   130    6.0     8.2   \n",
       "51            1           1           unknown   116    6.0     7.5   \n",
       "52            1           1           unknown   118    5.9     8.0   \n",
       "53            1           1           unknown   120    6.0     8.4   \n",
       "54            1           1           unknown   116    6.1     8.5   \n",
       "55            1           1           unknown   116    6.3     7.7   \n",
       "56            1           1           unknown   116    5.9     8.1   \n",
       "57            1           1           unknown   152    6.5     8.5   \n",
       "58            1           1           unknown   118    6.1     8.1   \n",
       "\n",
       "    color_score  \n",
       "0          0.55  \n",
       "1          0.59  \n",
       "2          0.60  \n",
       "3          0.80  \n",
       "4          0.79  \n",
       "5          0.77  \n",
       "6          0.81  \n",
       "7          0.81  \n",
       "8          0.92  \n",
       "9          0.89  \n",
       "10         0.93  \n",
       "11         0.92  \n",
       "12         0.88  \n",
       "13         0.70  \n",
       "14         0.69  \n",
       "15         0.69  \n",
       "16         0.67  \n",
       "17         0.73  \n",
       "18         0.83  \n",
       "19         0.85  \n",
       "20         0.86  \n",
       "21         0.84  \n",
       "22         0.87  \n",
       "23         0.88  \n",
       "24         0.75  \n",
       "25         0.75  \n",
       "26         0.74  \n",
       "27         0.77  \n",
       "28         0.72  \n",
       "29         0.81  \n",
       "30         0.79  \n",
       "31         0.82  \n",
       "32         0.80  \n",
       "33         0.74  \n",
       "34         0.75  \n",
       "35         0.75  \n",
       "36         0.76  \n",
       "37         0.79  \n",
       "38         0.77  \n",
       "39         0.75  \n",
       "40         0.78  \n",
       "41         0.79  \n",
       "42         0.82  \n",
       "43         0.70  \n",
       "44         0.72  \n",
       "45         0.72  \n",
       "46         0.71  \n",
       "47         0.72  \n",
       "48         0.72  \n",
       "49         0.73  \n",
       "50         0.71  \n",
       "51         0.72  \n",
       "52         0.72  \n",
       "53         0.74  \n",
       "54         0.71  \n",
       "55         0.72  \n",
       "56         0.73  \n",
       "57         0.72  \n",
       "58         0.70  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('Data2.txt', sep = \"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fruit_label\n",
       "0    38\n",
       "1    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('fruit_label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 0]\n",
      "[0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted as 0</th>\n",
       "      <th>Predicted as 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted as 0  Predicted as 1\n",
       "0              19               2\n",
       "1               3               6"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:, [\"mass\", \"width\", \"height\", \"color_score\"]]\n",
    "y = data.loc[:, \"fruit_label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size = 0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_test.values)\n",
    "print(y_pred)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred), index=[\"0\", \"1\"], columns=[\"Predicted as 0\", \"Predicted as 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements $M_{00}$ is called True Negative\n",
    "\n",
    "The elements $M_{10}$ is called False Negative\n",
    "\n",
    "The elements $M_{10}$ is called False Positive\n",
    "\n",
    "The elements $M_{11}$ is called True Positive\n",
    "\n",
    "```\n",
    "TN | FP\n",
    "__ . __\n",
    "FN | TP\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 True Positive Rate (Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the matrix by sum by **row**, we get True Negative Rate, True Positive Rate, False Negative Rate, False Positive Rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.904762  0.095238\n",
       "1  0.333333  0.666667"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = confusion_matrix(y_test, y_pred)\n",
    "M_normalized_by_row = M / np.sum(M, axis = 1).reshape((2, 1))\n",
    "pd.DataFrame(M_normalized_by_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "TNR | FPR\n",
    "___ . ___\n",
    "FNR | TPR\n",
    "```\n",
    "\n",
    "**TPR** is also called **Recall**.\n",
    "\n",
    "Hence,\n",
    "$$\n",
    "TPR = Recall = \\frac{TP}{TP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently $0 \\leq TPR \\leq 1$. A naive classifier guessing all data points belong to class 1 will have $TPR$ 1 and $FNR$ 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the matrix by sum by **columm**, we get another indicator called **Precision**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1\n",
       "0  0.863636  0.25\n",
       "1  0.136364  0.75"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = confusion_matrix(y_test, y_pred)\n",
    "M_normalized_by_col = M / np.sum(M, axis = 0).reshape((1, 2))\n",
    "pd.DataFrame(M_normalized_by_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    | \n",
    "___ . _________\n",
    "    | Precision\n",
    "```\n",
    "\n",
    "In other words,\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 $F_1$ Score\n",
    "\n",
    "$$\n",
    " \\frac{2}{F_1} = \\frac{1}{Precision} +  \\frac{1}{Recall}\n",
    "$$\n",
    "\n",
    "or equivalently\n",
    "$$\n",
    "F_1 = \\frac{2 Precision \\cdot Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "More generally,\n",
    "$$\n",
    "F_{\\beta} = (1 + \\beta^2) \\frac{Precision \\cdot Recall}{\\beta^2 \\cdot Precision + Recall}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly speaking, we can conclude a model is good if:\n",
    "- It has high recall, high precision\n",
    "- It has high TPR, TNR\n",
    "- It has high TPR, low FPR\n",
    "- It has high $F_1$ (or $F_\\beta$) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall\n",
      "0.6666666666666666\n",
      "Precision\n",
      "0.75\n",
      "F1\n",
      "0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print(\"Recall\")\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(\"Precision\")\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(\"F1\")\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 ROC Curve, ROC AUC for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some parametric method, we classify $x$ as of class 0 or 1 depending on some learned rule $f(x) < 0$ or $f(x) \\geq 0$. This is equivalent to $P(y = 1|x)$ less than or greater than 1/2 in some probabilistic method.\n",
    "\n",
    "If we replace $0$ and $1/2$ in these decision rule by another number, we will have different prediction, hence change TPR, TNR, precision and recall.\n",
    "\n",
    "When we represent $FPR, TPR$ on the same graph where our threshold for probabilistic method runs from 0 to 1, we will have different points. They are connected by a \"curve\" called **Receiver Characteristic Curve** (ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.0952381  0.0952381  0.14285714 0.14285714\n",
      " 0.38095238 0.38095238 1.        ]\n",
      "[0.11111111 0.55555556 0.55555556 0.77777778 0.77777778 0.88888889\n",
      " 0.88888889 1.         1.        ]\n",
      "[9.81619588e-01 7.19923154e-01 5.79287912e-01 4.97315906e-01\n",
      " 4.44425249e-01 4.44419952e-01 2.28812413e-01 2.28226503e-01\n",
      " 6.37427533e-08]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FPR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thresholds</th>\n",
       "      <td>0.981620</td>\n",
       "      <td>0.719923</td>\n",
       "      <td>0.579288</td>\n",
       "      <td>0.497316</td>\n",
       "      <td>0.444425</td>\n",
       "      <td>0.444420</td>\n",
       "      <td>0.228812</td>\n",
       "      <td>0.228227</td>\n",
       "      <td>6.374275e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5  \\\n",
       "FPR         0.000000  0.000000  0.095238  0.095238  0.142857  0.142857   \n",
       "TPR         0.111111  0.555556  0.555556  0.777778  0.777778  0.888889   \n",
       "Thresholds  0.981620  0.719923  0.579288  0.497316  0.444425  0.444420   \n",
       "\n",
       "                   6         7             8  \n",
       "FPR         0.380952  0.380952  1.000000e+00  \n",
       "TPR         0.888889  1.000000  1.000000e+00  \n",
       "Thresholds  0.228812  0.228227  6.374275e-08  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "print(fpr)\n",
    "print(tpr) \n",
    "print(thresholds)\n",
    "pd.DataFrame([fpr, tpr, thresholds], index=[\"FPR\", \"TPR\", \"Thresholds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd93c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code from Mr. Tiep Vu Huu's blog\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area under this curve is called AUC (Area Under the Curve). A model is good if this indicator is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9206349206349207"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Micro/macro-average Precision/Recall/F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"F3.png\"></img>\n",
    "\n",
    "where \n",
    "$$\n",
    "P(A, B) := \\frac{\\left| A \\cap B \\right|}{\\left|A\\right|}\n",
    "$$\n",
    "\n",
    "$$\n",
    "R(A, B) := \\frac{\\left| A \\cap B \\right|}{\\left|B\\right|} \n",
    "$$\n",
    "(Conventions vary on handling $B = \\emptyset$; this implementation uses $R(A, B):=0$, and similar for $P$.)\n",
    "$$\n",
    "F_\\beta(A, B) := \\left(1 + \\beta^2\\right) \\frac{P(A, B) \\times R(A, B)}{\\beta^2 P(A, B) + R(A, B)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('fruit_data_with_colors.txt', sep = \"\\t\")\n",
    "X = data.loc[:, [\"mass\", \"width\", \"height\", \"color_score\"]]\n",
    "y = data.loc[:, \"fruit_label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size = 0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "M = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.diagonal(M))/np.sum(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average recall\n",
      "0.4666666666666667\n",
      "Micro-average precision\n",
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Micro-average recall\")\n",
    "print(recall_score(y_test, y_pred, average='micro'))\n",
    "print(\"Micro-average precision\")\n",
    "print(precision_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average recall\n",
      "0.5178571428571428\n",
      "Macro-average precision\n",
      "0.5438311688311688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\ndoannguyen\\AppData\\Local\\Continuum\\anaconda2\\envs\\Tensorflow3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Macro-average recall\")\n",
    "print(recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"Macro-average precision\")\n",
    "print(precision_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] https://towardsdatascience.com/solving-a-simple-classification-problem-with-python-fruits-lovers-edition-d20ab6b071d2\n",
    "\n",
    "[2] https://machinelearningcoban.com/2017/02/11/binaryclassifiers/#-binary-classifiers-cho-multi-class-classification-problems\n",
    "\n",
    "[3] https://machinelearningcoban.com/2017/08/31/evaluation/\n",
    "\n",
    "[4] http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
